{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load the processed dataframes from the previous step\n",
    "# For this script, we assume df_lc, df_hc, and df_ieee are available pandas DataFrames.\n",
    "# In a real script, you would load them from saved files.\n",
    "\n",
    "# --- Heuristic Rule-Based Response Generation ---\n",
    "\n",
    "def generate_lc_response(row):\n",
    "    \"\"\"Generates a response for a Lending Club loan application.\"\"\"\n",
    "    risk_level = \"High\" if row['target'] == 1 else \"Low\"\n",
    "    justification_points =\n",
    "    mitigation_strategies =\n",
    "\n",
    "    # Justification logic\n",
    "    if row['fico_range_low'] < 660:\n",
    "        justification_points.append(f\"The applicant's FICO score of {row['fico_range_low']} is in the sub-prime range, indicating a higher credit risk.\")\n",
    "    if row['dti'] > 35:\n",
    "        justification_points.append(f\"The debt-to-income ratio of {row['dti']:.1f}% is elevated, suggesting a strained capacity to handle new debt.\")\n",
    "    if row['int_rate'] > 15:\n",
    "        justification_points.append(f\"The loan's interest rate of {row['int_rate']:.2f}% is high, which often reflects a pre-assessed higher risk by the platform.\")\n",
    "\n",
    "    if not justification_points and risk_level == \"High\":\n",
    "        justification_points.append(\"The loan was marked as high-risk based on historical outcome data, despite primary indicators appearing stable.\")\n",
    "    elif not justification_points and risk_level == \"Low\":\n",
    "        justification_points.append(\"The applicant presents a strong credit profile with a good FICO score, manageable DTI, and a reasonable interest rate.\")\n",
    "\n",
    "    # Mitigation logic for high-risk loans\n",
    "    if risk_level == \"High\":\n",
    "        mitigation_strategies.append(\"Consider denying the loan application due to the high probability of default.\")\n",
    "        mitigation_strategies.append(\"If approving, require additional collateral to secure the loan.\")\n",
    "        mitigation_strategies.append(\"Apply risk-based pricing by maintaining or increasing the high interest rate.\")\n",
    "        mitigation_strategies.append(\"Insert strict covenants into the loan agreement, such as restrictions on incurring further debt.\")\n",
    "\n",
    "    response_json = {\n",
    "        \"risk_level\": risk_level,\n",
    "        \"justification\": \" \".join(justification_points),\n",
    "        \"mitigation_strategies\": mitigation_strategies\n",
    "    }\n",
    "    return json.dumps(response_json, indent=2)\n",
    "\n",
    "def generate_ieee_response(row):\n",
    "    \"\"\"Generates a response for an IEEE transaction.\"\"\"\n",
    "    risk_level = \"High\" if row['target'] == 1 else \"Low\"\n",
    "    justification_points =\n",
    "    mitigation_strategies =\n",
    "\n",
    "    # Justification logic\n",
    "    if row > 1000:\n",
    "        justification_points.append(f\"The transaction amount of ${row:.2f} is significantly large and warrants scrutiny.\")\n",
    "    if row['P_emaildomain'] in ['mail.com', 'protonmail.com', 'anonymous.com']:\n",
    "        justification_points.append(f\"The purchaser's email domain ({row['P_emaildomain']}) is associated with a higher incidence of fraud.\")\n",
    "    if row['card6'] == 'charge card':\n",
    "        justification_points.append(\"The use of a charge card can sometimes be linked to fraudulent activities.\")\n",
    "\n",
    "    if not justification_points and risk_level == \"High\":\n",
    "        justification_points.append(\"The transaction was flagged as high-risk by the system based on complex patterns not immediately apparent from basic features.\")\n",
    "    elif not justification_points and risk_level == \"Low\":\n",
    "        justification_points.append(\"The transaction appears normal, with a standard amount and from a trusted domain.\")\n",
    "\n",
    "    # Mitigation logic for high-risk transactions\n",
    "    if risk_level == \"High\":\n",
    "        mitigation_strategies.append(\"Decline the transaction immediately to prevent financial loss.\")\n",
    "        mitigation_strategies.append(\"Flag the account for manual review by a fraud analyst.\")\n",
    "        mitigation_strategies.append(\"Trigger a multi-factor authentication step (e.g., SMS code) to verify the user's identity before proceeding.\")\n",
    "\n",
    "    response_json = {\n",
    "        \"risk_level\": risk_level,\n",
    "        \"justification\": \" \".join(justification_points),\n",
    "        \"mitigation_strategies\": mitigation_strategies\n",
    "    }\n",
    "    return json.dumps(response_json, indent=2)\n",
    "\n",
    "# --- Formatting Function ---\n",
    "\n",
    "def create_instruction_dataset(df, response_generator):\n",
    "    \"\"\"Creates a formatted instruction dataset from a dataframe.\"\"\"\n",
    "\n",
    "    instruction = \"You are an expert AI Risk Analyst. Your task is to evaluate the financial event detailed below. Provide a structured JSON response containing your risk assessment, a clear justification for your conclusion based on the provided data, and a list of actionable mitigation strategies.\"\n",
    "\n",
    "    dataset =\n",
    "    for _, row in df.iterrows():\n",
    "        # Serialize the row data into a human-readable context string\n",
    "        context_parts = [f\"- {col}: {val}\" for col, val in row.items() if col not in ['target']]\n",
    "        context = \"Financial Event Details:\\n\" + \"\\n\".join(context_parts)\n",
    "\n",
    "        # Generate the gold-standard response\n",
    "        response = response_generator(row)\n",
    "\n",
    "        # Format for SFTTrainer: create a text column with the full prompt\n",
    "        # We will use a chat template format that models like Llama 3 and Qwen understand.\n",
    "        text = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{instruction}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{context}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{response}<|eot_id|>\"\n",
    "        dataset.append({\"text\": text})\n",
    "\n",
    "    return Dataset.from_list(dataset)\n",
    "\n",
    "\n",
    "# --- Generate and Combine Datasets ---\n",
    "# Using smaller samples for demonstration purposes\n",
    "lc_sample = df_lc.sample(n=5000, random_state=42) if not df_lc.empty else pd.DataFrame()\n",
    "ieee_sample = df_ieee.sample(n=5000, random_state=42) if not df_ieee.empty else pd.DataFrame()\n",
    "\n",
    "# Create Hugging Face Datasets\n",
    "instruction_datasets =\n",
    "if not lc_sample.empty:\n",
    "    instruction_datasets.append(create_instruction_dataset(lc_sample, generate_lc_response))\n",
    "if not ieee_sample.empty:\n",
    "    instruction_datasets.append(create_instruction_dataset(ieee_sample, generate_ieee_response))\n",
    "# Note: A generator for Home Credit would be added here following the same pattern.\n",
    "\n",
    "if instruction_datasets:\n",
    "    # Concatenate all datasets into one\n",
    "    from datasets import concatenate_datasets\n",
    "    full_instruction_dataset = concatenate_datasets(instruction_datasets)\n",
    "\n",
    "    # Create a train/test split\n",
    "    final_dataset = full_instruction_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "    print(\"Instruction dataset created successfully.\")\n",
    "    print(f\"Total examples: {len(full_instruction_dataset)}\")\n",
    "    print(f\"Training examples: {len(final_dataset['train'])}\")\n",
    "    print(f\"Testing examples: {len(final_dataset['test'])}\")\n",
    "    print(\"\\n--- Sample Training Example ---\")\n",
    "    print(final_dataset['train']['text'])\n",
    "else:\n",
    "    print(\"Could not generate instruction dataset as no source data was available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
